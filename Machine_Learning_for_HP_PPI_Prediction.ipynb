{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ItunuIsewon/Machine_learning_for_host_pathogen_protein-protein_interaction_prediction_Tutorial/blob/main/Machine_Learning_for_HP_PPI_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Machine Learning for Host-Pathogen Protein-Protein Interaction Prediction.\n",
        "\n",
        "In this final notebook, we are going to demonstrate the efficiency of 6 different ML algorithms, namely: Logistic Regression, Support Vector Machine (SVM), Random Forest, XGBoost, LightGBM and Multiplayer perceptron, to predict HP-PPI using the features extracted in the previous notebook. We will demonstrate this using features extracted with the amino acid composition (AAC) descriptor."
      ],
      "metadata": {
        "id": "ROX_qBOTrDhS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install necessary packages"
      ],
      "metadata": {
        "id": "fN99lMWxrKE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mounting Google Drive to access files\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount ('/content/my_drive')\n",
        "\n",
        "#import pandas for data manipulation\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "Fb07yf0ArXJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1: Load and Prepare the dataset\n"
      ],
      "metadata": {
        "id": "J_FeU_8u6-Sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/my_drive/My Drive/HPI/Features'\n",
        "# Load the feature-extracted data\n",
        "df = pd.read_csv(file_path + \"/aac_features.csv\")\n",
        "\n",
        "# From the dataset, separate features (X) and label (y)\n",
        "X = df.drop(columns=['label'])  # feature matrix\n",
        "y = df['label']  # target vector\n"
      ],
      "metadata": {
        "id": "K-RFn9Fc7O9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2: Split the dataset\n",
        "In this step, we will divide our dataset into two parts:\n",
        "* 80% for training the model and\n",
        "* 20% for testing to evaluate the performace of the model.\n",
        "\n",
        "For spliting, we use stratified spliting to ensure that both the training data and testing data have the same proportion of positive and negative interaction pairs as in the original dataset."
      ],
      "metadata": {
        "id": "DPD7Z75T7mxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use stratified split to maintain class balance\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "14B71PgR-nba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3: Normalize the Data\n",
        "Some machine learning algorithms, such as SVM, Logistic Regression and MLP, are sensitive to the scale of input features, because large variations in the values of the features can impact their performance negatively.\n",
        "In this step, for these models, we normalize the data so that all features have the same scale"
      ],
      "metadata": {
        "id": "0UWyuyZp_C5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on training data, then transform both training and test data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "QAp9G0wpA8XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4: Define Machine Learning Models\n",
        "We define the ML models that will be trained to predict HP-PPIs. We selected these models because they are commonly used for classification tasks. These models also represent different learning strategies from linear models (Logistic Regression), Tree-based models (Random Forest, XGBoost, LightGBM) and Neural networks (MLP).\n",
        "\n",
        "Each of the model is initialized  with specific parameters to ensure stable performance and reproducibiity."
      ],
      "metadata": {
        "id": "2DCmKTGiBY8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Define all models in a dictionary\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),  # increased max_iter for convergence\n",
        "    \"SVM\": SVC(probability=True),  # enables probability outputs for AUC-ROC evaluation\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),  # random state for reproducibility\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),  # suppresses warning for newer versions\n",
        "    \"LightGBM\": LGBMClassifier(n_estimators=100, random_state=42),\n",
        "    \"MLP\": MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=300, random_state=42)  # a basic 2-layer neural network\n",
        "}\n"
      ],
      "metadata": {
        "id": "8KR_yHJAKeca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 5: Define Evaluation Function\n",
        "Evaluation Metrics: For each model, we will compute the following metrices:\n",
        "* Accuracy: Proportion of correct predictions.\n",
        "* Sensitivity (Recall): Proportion of true positives in all positive predictions.\n",
        "* Specificity: Proportion of true negatives in all negative predictions.\n",
        "* F1 Score: Harmonic mean of precision and recall.\n",
        "* Matthew's Correlation Coefficient (MCC): Measures correlation coefficient of true labels and predicted class.\n",
        "* AUROC: Area under the ROC curve"
      ],
      "metadata": {
        "id": "L4ebb60tLLiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, recall_score, f1_score,\n",
        "    matthews_corrcoef, roc_auc_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "# Evaluation function to calculate metrics\n",
        "def evaluate_model(name, y_true, y_pred, y_prob):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    metrics = {\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"Sensitivity\": recall_score(y_true, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) else 0,\n",
        "        \"F1 Score\": f1_score(y_true, y_pred),\n",
        "        \"MCC\": matthews_corrcoef(y_true, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_true, y_prob)\n",
        "    }\n",
        "    return metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "LRPkJjbBTb9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 6: Training, Prediction and Evaluation\n",
        "In this step, we will train the ML models on the training data and evaluate their performance using the test data.\n",
        "\n",
        "**Training:** Scaled data will be used for Logistic regression, SVM and MLP, while raw data will be used for Random Forest, XGBoost and LightGBM.\n",
        "\n",
        "**Prediction:** After training, the model is used to predict if the protein pairs in the test data are interacting or non-interacting.\n",
        "\n",
        "**Evaluation:** The performance of the model in predicting the interaction status of the test data is evaluated using the performance metrics defined above."
      ],
      "metadata": {
        "id": "TO7DHKasY04-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []  # Store results from all models\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n {name}\")\n",
        "\n",
        "    # Use scaled data for models that require it\n",
        "    if name in [\"SVM\", \"Logistic Regression\", \"MLP\"]:\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "    metrics = evaluate_model(name, y_test, y_pred, y_prob)\n",
        "    results.append(metrics)\n"
      ],
      "metadata": {
        "id": "91DvpwUYcmPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 7: Save the results"
      ],
      "metadata": {
        "id": "ie0XmCLZc8PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Save all metrics into a CSV file\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "results_df.to_csv(file_path + \"/AACmodel_evaluation_results.csv\", index=False)\n",
        "\n",
        "print(\"Results saved\")\n"
      ],
      "metadata": {
        "id": "FIvyqNjMdIFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 8: Visualising Model Evaluation Metrics\n"
      ],
      "metadata": {
        "id": "HT7llZSZdKQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using Clustered Column Chart (Grouped Bar Chart)"
      ],
      "metadata": {
        "id": "pVRu7mxPCABp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the evaluation results\n",
        "results_df = pd.read_csv(file_path + \"/AACmodel_evaluation_results.csv\")\n",
        "\n",
        "# Metrics to plot\n",
        "metrics = [\"Accuracy\", \"Sensitivity\", \"Specificity\", \"F1 Score\", \"MCC\", \"AUC-ROC\"]\n",
        "\n",
        "# Melt the DataFrame for grouped bar plotting\n",
        "df_melted = results_df.melt(id_vars=[\"Model\"],\n",
        "                            value_vars=metrics,\n",
        "                            var_name=\"Metric\",\n",
        "                            value_name=\"Score\")\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=df_melted, x=\"Metric\", y=\"Score\", hue=\"Model\", palette=\"Set2\")\n",
        "\n",
        "plt.title(\"AAC Evaluation Metrics Across Models\", fontsize=16)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.ylim(0, 1)  # since most metrics range between 0 and 1\n",
        "plt.legend(title=\"Model\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1AzhkLpxhk_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###HeatMap"
      ],
      "metadata": {
        "id": "vGWWCsEkCjWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load your results\n",
        "results_df = pd.read_csv(file_path + \"/AACmodel_evaluation_results.csv\")\n",
        "\n",
        "# Set the model names as index\n",
        "results_df.set_index(\"Model\", inplace=True)\n",
        "\n",
        "# Select only metric columns (excluding 'Model' if still present)\n",
        "metrics = [\"Accuracy\", \"Sensitivity\", \"Specificity\", \"F1 Score\", \"MCC\", \"AUC-ROC\"]\n",
        "heatmap_data = results_df[metrics]\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(heatmap_data, annot=True, fmt=\".3f\", cmap=\"YlGnBu\", cbar_kws={\"label\": \"Score\"})\n",
        "\n",
        "plt.title(\"AAC Model Performance Heatmap\", fontsize=16)\n",
        "plt.xlabel(\"Metrics\")\n",
        "plt.ylabel(\"Models\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WilqKrKhiNq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 9: Cross Validation\n",
        "Cross validation is another way of training and evaluating the performance of the ML models. Unlike the single train-test split, the model is tested on different subset (fold) of the data and performance is avaerage over the multiple folds.\n",
        "\n",
        "In K-fold cross validation:\n",
        "* The dataset is divided into k equal part (k here is  10).\n",
        "* The ML model are trained on k-1 folds (in this case 9) and tested on the remaining one.\n",
        "* This process is repeated k times, each with a different test fold every time.\n",
        "* The final evaluation metrics will then be calculated as the average score across all 10 folds"
      ],
      "metadata": {
        "id": "WBplR0uymvWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# Number of folds\n",
        "k = 10\n",
        "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Dictionary to store averaged results\n",
        "cv_results = []\n",
        "\n",
        "# Loop through models\n",
        "for name, model in models.items():\n",
        "    print(f\"Cross-validating: {name}\")\n",
        "\n",
        "    # Lists to hold fold scores\n",
        "    accs, sens, specs, f1s, mccs, aucs = [], [], [], [], [], []\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        # Scale data if needed\n",
        "        if name in [\"SVM\", \"Logistic Regression\", \"MLP\"]:\n",
        "            scaler = StandardScaler()\n",
        "            X_train = scaler.fit_transform(X_train)\n",
        "            X_val = scaler.transform(X_val)\n",
        "\n",
        "        # Fit model and predict\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "        y_prob = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        # Confusion matrix\n",
        "        tn = ((y_val == 0) & (y_pred == 0)).sum()\n",
        "        fp = ((y_val == 0) & (y_pred == 1)).sum()\n",
        "        fn = ((y_val == 1) & (y_pred == 0)).sum()\n",
        "        tp = ((y_val == 1) & (y_pred == 1)).sum()\n",
        "\n",
        "        # Store scores\n",
        "        accs.append(accuracy_score(y_val, y_pred))\n",
        "        sens.append(recall_score(y_val, y_pred))\n",
        "        specs.append(tn / (tn + fp) if (tn + fp) else 0)\n",
        "        f1s.append(f1_score(y_val, y_pred))\n",
        "        mccs.append(matthews_corrcoef(y_val, y_pred))\n",
        "        aucs.append(roc_auc_score(y_val, y_prob))\n",
        "\n",
        "    # Save average metrics\n",
        "    cv_results.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": np.mean(accs),\n",
        "        \"Sensitivity\": np.mean(sens),\n",
        "        \"Specificity\": np.mean(specs),\n",
        "        \"F1 Score\": np.mean(f1s),\n",
        "        \"MCC\": np.mean(mccs),\n",
        "        \"AUC-ROC\": np.mean(aucs),\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "cv_df = pd.DataFrame(cv_results)\n",
        "cv_df.to_csv(file_path + \"/cross_validated_results.csv\", index=False)\n",
        "print(\"Cross-validated results saved as 'cross_validated_results.csv'\")\n"
      ],
      "metadata": {
        "id": "841oW7iZmz0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set plot style\n",
        "plt.figure(figsize=(12, 6))\n",
        "heatmap_data = cv_df.set_index(\"Model\")  # use Model names as row labels\n",
        "\n",
        "# Round the values for cleaner display\n",
        "heatmap_data_rounded = heatmap_data.round(3)\n",
        "\n",
        "# Create the heatmap\n",
        "sns.heatmap(\n",
        "    heatmap_data_rounded,\n",
        "    annot=True,         # show values in cells\n",
        "    fmt=\".3f\",          # format decimals\n",
        "    cmap=\"YlGnBu\",      # color map\n",
        "    linewidths=0.5,     # lines between cells\n",
        "    cbar_kws={'label': 'Score'}\n",
        ")\n",
        "\n",
        "plt.title(\"Cross-Validated Performance Metrics (Mean Scores)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3heTvPd6oGk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 10: Model Deploymment\n",
        "After identifying the best performing model based on the evaluation metrics from single split training and cross validation, we will retrain the best model using the entire dataset and save the model for reuse on new data without the need for retraining"
      ],
      "metadata": {
        "id": "HpJRgWJowYOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hyperparameter Tuning\n",
        "Based on our model evaluation result, XGBoost gave the best performance. Here, the hyperparameters of XGBoost is tuned to identify the best parameters to use for model deployment"
      ],
      "metadata": {
        "id": "7qJDQK2IPrs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define base model\n",
        "xgb = XGBClassifier(\n",
        "    objective=\"binary:logistic\",\n",
        "    eval_metric=\"logloss\",\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"subsample\": [0.7, 0.8, 1.0],\n",
        "    \"colsample_bytree\": [0.7, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Perform grid search (10-fold CV)\n",
        "grid_cv = GridSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_grid=param_grid,\n",
        "    cv=10,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_cv.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_cv.best_params_)\n",
        "print(\"Best cross-validated score:\", grid_cv.best_score_)\n"
      ],
      "metadata": {
        "id": "qYrVLEiFP5ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train the final Model on the entire dataset\n",
        "We will now retrain this model using the entire dataset (training data and testing data combined) with the best parameters."
      ],
      "metadata": {
        "id": "D835t7GH5NkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Convert NumPy arrays back to DataFrames if needed\n",
        "if isinstance(X_train, np.ndarray):\n",
        "    X_train = pd.DataFrame(X_train, columns=X.columns)\n",
        "if isinstance(X_test, np.ndarray):\n",
        "    X_test = pd.DataFrame(X_test, columns=X.columns)\n",
        "\n",
        "# Combine them safely\n",
        "X_full = pd.concat([X_train, X_test], ignore_index=True)\n",
        "y_full = pd.concat([y_train, y_test], ignore_index=True)\n",
        "\n",
        "\n",
        "# Use the best parameters obtained from above\n",
        "best_params = grid_cv.best_params_\n",
        "\n",
        "# Train final model on full training data\n",
        "final_xgb = XGBClassifier(\n",
        "    objective=\"binary:logistic\",\n",
        "    eval_metric=\"logloss\",\n",
        "    use_label_encoder=False,\n",
        "    **best_params\n",
        ")\n",
        "\n",
        "final_xgb.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "99jETHc05UXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Save the best model"
      ],
      "metadata": {
        "id": "g_dWN6kSxjz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "import joblib\n",
        "# Save the trained model\n",
        "# Specify your desired file path\n",
        "save_path = \"/content/my_drive/My Drive/HPI/Features/final_xgb.pkl\"\n",
        "\n",
        "joblib.dump(final_xgb, save_path)\n",
        "\n",
        "print(\"Model saved successfully!\")\n"
      ],
      "metadata": {
        "id": "LfBfhpKp_BeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Use the Saved Model on New Dataset\n",
        "Once saved, it can be used to make predictions of new HPPPI pair/pairs.\n",
        "\n",
        "Note: The model was trained using Amino Acid Composition (AAC) features, thus, the model can only be used to make predictions on new data with AAC features."
      ],
      "metadata": {
        "id": "TnnzlhF3_OeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Making predictions on new HP-PPI pairs\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load the model\n",
        "model = joblib.load(\"/content/my_drive/My Drive/HPI/Features/final_xgb.pkl\")\n",
        "\n",
        "# Load  new data (AAC features only)\n",
        "new_data = pd.read_csv(\"new_hppi_aac_features.csv\")\n",
        "predictions = model.predict(new_data)\n",
        "\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "id": "mJh3JjJz34Rk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}